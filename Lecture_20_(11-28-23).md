# Lecture 20

## Synchronization

### Threads

* Process level concurrency with fork() is powerful but infelxible
  * The OS schedules the task, incuring context switching overhead
  * The proess memory is opied making it hard to share data among tasks.

* A **thread** is a concurrency primitive that is inner-process
  * The program itself schedules the task as part of the same process
  * Process memory, therefore, is shared across all threads

### Fork in action

* Fork copies the memory layout and capies the process state (but gives it a unique ID)

![image](https://github.com/clester331/0449/assets/122314614/2d471962-6d2c-4ac8-bc0c-e980430b547e)

* Threads will still retain much of the address space
  * Threads share code/data/etc/ however, they have their own stack and CPU state
  * They execute in parallel with one another interacting directly with the same data
 
### libpthread

* The 2011 amendment to C standard (C11) added a threading API
* We will be reviewing the pthread standard
  * The C11 threads.h API is still very similar
  * There are ports of the pthread.h interface to many OSes
  * Lots of threading APIs in other languages emulate it
 
### POSIX   

* The "p" is pthread stands for the Portable Operating System Interface (POSIX)
  * This is a standard for creating OS abstractions
  * Intended to lower the burden of porting applications

* POSIX standardizes threads, but also process creating and behavior of fork, file abstractions, and how data is shared among processes

### Weaving a thread

![image](https://github.com/clester331/0449/assets/122314614/51d415a3-6c2b-4537-8969-1f5c08c87f39)

* main is within the main thread()
* The pthread_create function creates a second thread, which runs alongside the main thread
  * The first argument is the address of a variable to hold the thread ID
  * The NULL is where you can add some flags, but the defaults are OK
  * The thread is the function to use
  * The last argument is passed to that funcion and generally an address
 
* When the process exits normally, all threads are also cancelled, even if they haven't completed
* In this run, the second thread never prints its message

```cmd
> ./thrd_bad
Done!
```

![image](https://github.com/clester331/0449/assets/122314614/695b2141-301e-4128-8b4b-1cc6fb9a98e6)
 
 * pthread_join() waits for the given thread to exit by thread ID
   * The NULL is, again, optional flags
* Here, the main thread waits until the function completes
* It prints out the string given by the argument

```cmd
> ./thrd
Hello, students!
Done!
```

* Unlike process-level concurrency using fork(), threads share memory
* Each thread, here, shares access to the same global variable counter
  * When the main thread updates, the secondary thread sees that value
* Threads share the same virtual address space and page table
  * They only have their own stack and CPU state   

![image](https://github.com/clester331/0449/assets/122314614/44833fb6-c573-4f14-b690-fdc26f91477a)

![image](https://github.com/clester331/0449/assets/122314614/9735aa4c-36f2-437b-94f3-d6fb3302145e)

## Synchronization

* The rail system requires alot of attention to detail to provide
  * Orderly and timely scheduling of trains
  * Shared use of a single resource: rail
  * Coordination with trains and competiing interests
 
* In order to provide this, trains make use of signals and switching areas
  * Trains wait while others pass, all agreeing on the nature of signals
  * The signals are called **semaphores**

### Seminal Semaphore

* A **semaphore** is a special counter used for synchronization
* The counter is a signed integer that often starts at zero or one
* Two defined operations:
  * Up (signal/release)
  * Down (wait/acquire)
* These operations often have different names or are abbreviated
  * V -> release
  * P -> pass   

### Preventing Derailment

* sem_init() creates a new semaphore
  * The first argument is an address to a variable that will hold the semaphore data.
  * The second arguent, when 0, means that other thread can see the semaphore. Non-zero means other threads cannot interact with the semaphore, which is a bit more advanced
  * The third argument is the initial value (1)
 
* sem_wait() decrements the counter
  * Waits to dcrement if the counter is 0
* sem_post() increments the counter
  * May release a thread waiting at sem_wait()
* When both threads hit sem_wait() at the same time, only one continues
* When one sets the lock, the other waits.
  * The other thread relies on the first to eventually release the lock using sem_post()
  * When this happens, the other thread can go
* The lock/unlock pattern creates a **critical section**, a piece of code that has the garuntee that only one task can enter at a time

### Mutex

* A simple critical section just needs a counter that covers 0 and 1
* A **mutex** is a special boolean used for synchronization
  * Short for "mutual exclusion", a term for when two things can only have one resource at a time
* There are two defined operations:
  * lock / wait; only proceedes if the mutex is unlocked
  * unlock / release; unlocks the mutex
* A mutex can be created using a semaphore
  * Provides a subset of the capabilities of the more gneral semaphore
 
### Using a mutex to prevent derailing

* Mutexes are useful for locking simple resources
  * It follows much the same pattern as semaphores, and perhaps easier to understand
* pthread_mutex_init() creates the mutex similarly to sem_init()
* pthread_mutex_lock() and pthread_mutex_nulock() do the locking and unlocking, as expected

#### Strategies

* Semaphores and mutexes are both primitives to aid in concurrent programming
* We saw, here, another example of a **race condition**, a concurrency bug where the absence of garunteed order can result in incorrect behavior
  * Namely, threads being interrupted in-between operations that need to happen together and racing another thread that will incorrectly use that intermediate value  

## Parallel Pitfalls

### Resources/Intersection

* Metaphor: intersection
* The intersection is a shared resource, much like a device or the CPU
* Multiplexing the intersection is important to avoid crashes
* When the streets aren't busy, cars just make it safely accross

![image](https://github.com/clester331/0449/assets/122314614/4bfff039-f85c-4c6a-9fb1-3dbc8a7465d3)

* However, in some circumstances, several cars may reach the intersection at the same time
* If there is no previously defined way to handlet this, they all wait for others to get out of the way
* **Deadlock** occurs when multiple tasks are waiting for each other, making no process

#### How to solve deadlock

* Deadlock is a bug that needs extra consideration to avoid
* In this case, you need some method of making only some of the cars (tasks) wait, while letting others go
  * (traffic lights)
* Beyond defining order, synchronization helps avoid these type of logical errors

![image](https://github.com/clester331/0449/assets/122314614/960b0b4b-30b6-4540-9212-db4051465d5a)

* Another issue related to the deadlock is **starvation** where the system makes progress byt one task is perpetually delayed
* When some tasks have priority over resources, they may not give them up for other tasks (those tasks wait *forever*)
* Starvation can happen in situations where "fairness" scheduling goes awry
* If you have a webserver, the OS might schedule that process whenever there is some incoming requests
* Preventing starvation might be keeping track of how much time a process has a resource and how long it has waited in line 

### Livelock

* Example: there is a narrow hallway, and there are two polite people. Thy walk towards each other and try to get out of each other's way, but they keep insiting the other to go ahead of them
* This is a **livelock**, where two tasks are actively signaling the other to go and make no progress as a result

#### Deadlock vs Livelock

* In deadlock, all tasks are waiting for a signal that will never happen (they actively do nothing)
* In contrast, livelock occurs when each task signals the other, and they respond by signaling back
* Detecting that your program has a deadlock or livelock is tricky

#### Solving things

* Proper synchroniztion and planning can solve all these issues
  * Deadlock: avoid patterns of critical sections that depend on each other
  * Lovelock: establish a tie-breaking mechanism (thread with smallest id goes first)
 
welp, thats it
